{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92fb2d7b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Finished recording.\n",
      "Hello, JetJPT. I want you to create a contract for me. The contract will be by and between me and my cousin to attain our goals in exercise. Please write a contract in which it is agreed upon that we will do a weekly exercise of a total of 150 minutes. Make it simple, pragmatic and place it under the German jurisdiction. The contract will go on for one year. Leave out blanks to fill the dates, please.\n",
      "**EXERCISE CONTRACT**\n",
      "\n",
      "This Agreement (\"Contract\") is made this ____ day of _______, 20____, by and between __________(\"First Party\") and ___________(\"Second Party\"). Both parties herein are also referred herein as (\"Party\") or collectively as the (\"Parties\").\n",
      "\n",
      "**I. AGREEMENT:**\n",
      "\n",
      "1. The Parties hereby confirm and agree to engage in a minimum total of One Hundred Fifty (150) minutes of exercise every week for the duration of One (1) year effective from the date added on top of this Agreement.\n",
      "\n",
      "**II. DURATION:**\n",
      "\n",
      "1. This Contract is to commence on the date as specified above and shall continue for a period of One (1) Year unless sooner terminated as provided herein or amended in writing signed by both Parties.\n",
      "\n",
      "**III. TERMS AND CONDITIONS:**\n",
      "\n",
      "1. Each Party will provide tangible proof of their completion of their weekly minutes either via automatic tracking device or manual logging.\n",
      "   \n",
      "2. Both Parties shall mutually agree upon the type/s of exercise that will be performed every week.\n",
      "   \n",
      "3. Should any Party fail to complete the agreed-upon weekly exercise minutes, a makeup period of the following week will be allowed.\n",
      "\n",
      "**IV. TERMINATION:**\n",
      "\n",
      "1. Notwithstanding the dates set out herein, either Party may terminate this Contract on two month's written notice to the other Party.\n",
      "\n",
      "**V. GOVERNING LAW:**\n",
      "\n",
      "1. This Contract shall be governed by and construed in accordance with the laws of Germany.\n",
      "\n",
      "____________________                   \n",
      "[First Party]\n",
      "\n",
      "____________________                   \n",
      "[Second Party]\n",
      "\n",
      "**DISCLAIMER: This contract template is for reference purposes only and does not constitute legal advice. If you need legal help, please seek advice from a professional lawyer.**\n",
      "\n",
      "Recording...\n",
      "Finished recording.\n",
      "MBC 뉴스 이덕영입니다.\n",
      "안녕하세요, 이덕영님. 어떻게 도와드릴까요?\n",
      "Recording...\n",
      "Finished recording.\n",
      "시청해 주셔서 감사합니다.\n",
      "당신의 시청에 감사드립니다, 이덕영님. 다른 도움이 필요하시면 언제든지 말씀해주세요.\n",
      "Recording...\n",
      "Finished recording.\n",
      "MBC 뉴스 이덕영입니다.\n",
      "안녕하세요, 이덕영님. MBC 뉴스를 참조하시는 군요. 어떤 정보를 찾고 계신가요?\n",
      "Recording...\n",
      "Finished recording.\n"
     ]
    },
    {
     "ename": "InvalidRequestError",
     "evalue": "Audio file is too short. Minimum audio length is 0.1 seconds.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 98\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;28mprint\u001b[39m(transcript[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     95\u001b[0m         \u001b[38;5;28mprint\u001b[39m(responses\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m---> 98\u001b[0m \u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menviron\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOPENAI_API_KEY\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 74\u001b[0m, in \u001b[0;36mchat\u001b[1;34m(model, api_key)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m#Utilize Whisper for transcription\u001b[39;00m\n\u001b[0;32m     73\u001b[0m audio_file\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 74\u001b[0m transcript \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAudio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranscribe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwhisper-1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m#feed transript into conversation\u001b[39;00m\n\u001b[0;32m     77\u001b[0m user_input \u001b[38;5;241m=\u001b[39m transcript[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\openai\\api_resources\\audio.py:65\u001b[0m, in \u001b[0;36mAudio.transcribe\u001b[1;34m(cls, model, file, api_key, api_base, api_type, api_version, organization, **params)\u001b[0m\n\u001b[0;32m     55\u001b[0m requestor, files, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_request(\n\u001b[0;32m     56\u001b[0m     file\u001b[38;5;241m=\u001b[39mfile,\n\u001b[0;32m     57\u001b[0m     filename\u001b[38;5;241m=\u001b[39mfile\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m     63\u001b[0m )\n\u001b[0;32m     64\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_get_url(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranscriptions\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 65\u001b[0m response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m util\u001b[38;5;241m.\u001b[39mconvert_to_openai_object(\n\u001b[0;32m     67\u001b[0m     response, api_key, api_version, organization\n\u001b[0;32m     68\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\openai\\api_requestor.py:226\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    207\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    214\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    215\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    216\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[0;32m    217\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[0;32m    218\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    224\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[0;32m    225\u001b[0m     )\n\u001b[1;32m--> 226\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\openai\\api_requestor.py:620\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    612\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    613\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    614\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    615\u001b[0m         )\n\u001b[0;32m    616\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[0;32m    617\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    619\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m--> 620\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    621\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    623\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    624\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    625\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    626\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    627\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\openai\\api_requestor.py:683\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    681\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[0;32m    682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[1;32m--> 683\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[0;32m    684\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[0;32m    685\u001b[0m     )\n\u001b[0;32m    686\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mInvalidRequestError\u001b[0m: Audio file is too short. Minimum audio length is 0.1 seconds."
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "import pyaudio\n",
    "import wave\n",
    "import numpy as np\n",
    "import webrtcvad\n",
    "\n",
    "\n",
    "def chat(model, api_key):\n",
    "    # Authenticate with OpenAI\n",
    "    openai.api_key = api_key\n",
    "    \n",
    "    # Create a list of dictionaries to store the conversation history\n",
    "    conversation = [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}]\n",
    "    \n",
    "    # Loop through the conversation\n",
    "    while True:\n",
    "        \n",
    "        # Get user input as recording\n",
    "        CHUNK = 160\n",
    "        FORMAT = pyaudio.paInt16\n",
    "        CHANNELS = 2\n",
    "        RATE = 16000\n",
    "        SILENCE_LIMIT = 2  # Time of silence needed to stop recording (seconds)\n",
    "        WAVE_OUTPUT_FILENAME = \"input.wav\"\n",
    "\n",
    "        vad = webrtcvad.Vad()\n",
    "        vad.set_mode(3)\n",
    "    \n",
    "        audio = pyaudio.PyAudio()\n",
    "\n",
    "        stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                        rate=RATE, input=True,\n",
    "                        frames_per_buffer=CHUNK)\n",
    "\n",
    "        print(\"Recording...\")\n",
    "\n",
    "        frames = []\n",
    "        silent_count = 0\n",
    "    \n",
    "        while True:\n",
    "            data = stream.read(CHUNK)\n",
    "            \n",
    "            #Check for speech\n",
    "            decoded_data = np.frombuffer(data, dtype=np.int16)\n",
    "            audio_level = np.max(decoded_data)\n",
    "\n",
    "            if  vad.is_speech(data, RATE):\n",
    "                silent_count = 0\n",
    "                \n",
    "                frames.append(data)\n",
    "            else:\n",
    "                silent_count += 1\n",
    "            \n",
    "            # Check if there's been enough silence to stop recording\n",
    "            if silent_count > SILENCE_LIMIT * RATE / CHUNK:\n",
    "                break\n",
    "\n",
    "        print(\"Finished recording.\")\n",
    "\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "        audio.terminate()\n",
    " \n",
    "        waveFile = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "        waveFile.setnchannels(CHANNELS)\n",
    "        waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "        waveFile.setframerate(RATE)\n",
    "        waveFile.writeframes(b''.join(frames))\n",
    "        waveFile.close()\n",
    "        \n",
    "        #Utilize Whisper for transcription\n",
    "        audio_file= open(\"input.wav\", \"rb\")\n",
    "        transcript = openai.Audio.transcribe(\"whisper-1\", audio_file)\n",
    "        \n",
    "        #feed transript into conversation\n",
    "        user_input = transcript[\"text\"]\n",
    "        conversation.append(\n",
    "        {\"role\": \"user\", \"content\": user_input}\n",
    "        )\n",
    "        \n",
    "        # Generate the model responses\n",
    "        responses = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            messages=conversation\n",
    "        )\n",
    "        \n",
    "        # save the models response\n",
    "        prime_response = responses.choices[0].message[\"content\"]\n",
    "        conversation.append({\"role\": \"assistant\", \"content\":prime_response}\n",
    "        )\n",
    "        \n",
    "        # Print the model's response\n",
    "        print(transcript[\"text\"])\n",
    "        print(responses.choices[0].message[\"content\"])\n",
    "        \n",
    "\n",
    "chat(model=\"gpt-4\", api_key=os.environ[\"OPENAI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024f8e94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addbb07e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
