{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fb2d7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello!\n",
      "Hi there! How can I assist you today?\n",
      "Is this api call successful?\n",
      "I'm sorry, but I would need more information about the API call you are referring to in order to determine whether it was successful or not. Can you provide me with the API call and any error messages or responses received?\n",
      "Oh I mean our conversation right now\n",
      "Yes, this conversation is successful. I am able to understand and respond to your messages without any errors. Is there anything else I can help you with?\n",
      "Let us try your memory of the conversation, okay?\n",
      "Sure, I'll do my best!\n",
      "what was my initial quesion?\n",
      "Your initial question was \"Is this api call successful?\"\n",
      "good bot\n",
      "Thank you! I'm always here to assist you with any questions or tasks you need help with.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "def chat(model, api_key):\n",
    "    # Authenticate with OpenAI\n",
    "    openai.api_key = api_key\n",
    "    \n",
    "    # Create a list of dictionaries to store the conversation history\n",
    "    conversation = [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}]\n",
    "    \n",
    "    # Loop through the conversation\n",
    "    while True:\n",
    "        \n",
    "        # Get user input\n",
    "        user_input = input()\n",
    "        conversation.append(\n",
    "            {\"role\": \"user\", \"content\": user_input}\n",
    "        )\n",
    "        \n",
    "        # Generate the model responses\n",
    "        responses = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            messages=conversation\n",
    "        )\n",
    "        \n",
    "        # save the models response\n",
    "        prime_response = responses.choices[0].message[\"content\"]\n",
    "        conversation.append({\"role\": \"assistant\", \"content\":prime_response}\n",
    "        )\n",
    "        \n",
    "        # Print the model's response\n",
    "        print(responses.choices[0].message[\"content\"])\n",
    "        \n",
    "\n",
    "chat(model=\"gpt-3.5-turbo\", api_key=os.environ[\"OPENAI_API_KEY\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
